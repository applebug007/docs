---
title: 'GenAI Image and Content Detection'
description: 'Detect synthetic media from popular AI platforms like Google Veo 3, Midjourney, Kling and more'
---
## Supported AI Platforms

<CardGroup cols={2}>
  <Card
    title="Image Generators"
    icon="image"
  >
    Midjourney, DALL-E, Stable Diffusion, Adobe Firefly, and more
  </Card>
  <Card
    title="Video Generators"
    icon="video"
  >
    Google Veo 3, OpenAI Sora, Runway ML, Kling AI, and emerging platforms
  </Card>
  <Card
    title="Text Generators"
    icon="file-text"
  >
    GPT models, Claude, Gemini, and other large language models
  </Card>
  <Card
    title="Audio Generators"
    icon="music"
  >
    ElevenLabs, Murf, Synthesia voice, and AI music generators
  </Card>
</CardGroup>

## Detection Capabilities

### Image Analysis
Our image detection system can identify content generated by:

- **Midjourney** - Popular Discord-based image generator
- **DALL-E 2/3** - OpenAI's image generation models
- **Stable Diffusion** - Open-source diffusion models
- **Adobe Firefly** - Adobe's commercial AI art tool
- **Leonardo AI** - Gaming and art-focused generator
- **Bing Image Creator** - Microsoft's AI image tool

**Detection Methods**:
- Noise pattern analysis unique to each platform
- Compression artifact identification
- Style and aesthetic fingerprinting
- Metadata extraction and validation

### Video Analysis
Detect synthetic videos from emerging platforms:

- **Google Veo 3** - Google's latest video generation model
- **OpenAI Sora** - High-quality video generation
- **Runway ML** - Professional video AI tools
- **Kling AI** - Advanced Chinese video generation
- **Pika Labs** - Short-form video generation
- **Stable Video Diffusion** - Open-source video models

**Detection Methods**:
- Temporal consistency analysis
- Generation artifact identification
- Motion pattern analysis
- Frame-by-frame authenticity scoring

### Text Analysis
Identify AI-generated text content:

- **GPT Models** (GPT-3.5, GPT-4, and variants)
- **Claude** (Anthropic's AI assistant)
- **Gemini** (Google's language model)
- **PaLM** (Google's Pathways Language Model)
- **LLaMA** (Meta's Large Language Model)

**Detection Methods**:
- Writing pattern analysis
- Perplexity scoring
- Linguistic fingerprinting
- Coherence and flow analysis

## API Integration

### Health Check

```bash
GET /health
```

Check if the AI Image Detection service is running:

**Response:**
```json
{
  "status": "healthy"
}
```

### Detect AI-Generated Images (Base64)

```bash
POST /predict?model_name=default&model_version=v0.1
```

Analyze images for AI generation using Base64 encoded image data:

**Request:**
```json
{
  "task_id": "unique_task_identifier",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "data": {
    "type": "image",
    "payload": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg=="
  }
}
```

### Detect AI-Generated Images (URL)

```bash
POST /predict?model_name=default&model_version=v0.1
```

Analyze images for AI generation using image URL:

**Request:**
```json
{
  "task_id": "unique_task_identifier", 
  "timestamp": "2024-01-15T10:30:00.000Z",
  "data": {
    "type": "image",
    "payload": "https://example.com/image.jpg"
  }
}
```

### Request Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `model_name` | string | No | Model name to use (default: "default") |
| `model_version` | string | No | Model version (default: "v0.1") |
| `task_id` | string | Yes | Unique identifier for the detection task |
| `timestamp` | string | Yes | ISO 8601 timestamp of the request |
| `data.type` | string | Yes | Data type - must be "image" |
| `data.payload` | string | Yes | Base64 encoded image or image URL |

## Response Format

### Image Detection Response

The API returns a JSON response with detection results:

```json
{
  "task_id": "unique_task_identifier",
  "status": "completed",
  "timestamp": "2024-01-15T10:30:05.123Z",
  "result": {
    "is_ai_generated": true,
    "confidence_score": 0.92,
    "detected_platform": "midjourney",
    "platform_confidence": 0.87,
    "analysis_summary": {
      "image_authenticity": "synthetic",
      "generation_likelihood": "high",
      "human_likelihood": "low"
    }
  },
  "processing_time_ms": 1247
}
```

### Success Response Fields

| Field | Type | Description |
|-------|------|-------------|
| `task_id` | string | The unique task identifier from the request |
| `status` | string | Processing status: "completed", "processing", "failed" |
| `timestamp` | string | ISO timestamp when processing completed |
| `result.is_ai_generated` | boolean | Whether the image is AI-generated |
| `result.confidence_score` | number | Overall confidence (0.0 - 1.0) |
| `result.detected_platform` | string | Identified AI platform (if detected) |
| `result.platform_confidence` | number | Platform detection confidence (0.0 - 1.0) |
| `processing_time_ms` | number | Time taken to process the request |

### Error Response

If there's an error in processing, the API returns:

```json
{
  "task_id": "unique_task_identifier",
  "status": "failed",
  "timestamp": "2024-01-15T10:30:05.123Z",
  "error": {
    "code": "INVALID_IMAGE",
    "message": "Unable to process the provided image data",
    "details": "Image format not supported or corrupted data"
  }
}
```

### Code Examples

<CodeGroup>

```bash cURL
# Health Check
curl -X GET "http://localhost:8000/health"

# Detect AI Image (Base64)
curl -X POST "http://localhost:8000/predict?model_name=default&model_version=v0.1" \
  -H "Content-Type: application/json" \
  -d '{
    "task_id": "test_image_001",
    "timestamp": "2024-01-15T10:30:00.000Z",
    "data": {
      "type": "image",
      "payload": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg=="
    }
  }'

# Detect AI Image (URL)
curl -X POST "http://localhost:8000/predict?model_name=default&model_version=v0.1" \
  -H "Content-Type: application/json" \
  -d '{
    "task_id": "test_image_002",
    "timestamp": "2024-01-15T10:30:00.000Z",
    "data": {
      "type": "image",
      "payload": "https://example.com/suspicious-image.jpg"
    }
  }'
```

```python Python
import requests
import json
from datetime import datetime
import base64

# API Configuration
BASE_URL = "http://localhost:8000"
MODEL_NAME = "default"
MODEL_VERSION = "v0.1"

def health_check():
    """Check if the API is healthy"""
    response = requests.get(f"{BASE_URL}/health")
    return response.json()

def detect_ai_image_base64(image_path, task_id=None):
    """Detect AI generation in image using base64"""
    # Read and encode image
    with open(image_path, "rb") as image_file:
        image_data = base64.b64encode(image_file.read()).decode('utf-8')
    
    payload = {
        "task_id": task_id or f"task_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "timestamp": datetime.now().isoformat() + "Z",
        "data": {
            "type": "image",
            "payload": image_data
        }
    }
    
    response = requests.post(
        f"{BASE_URL}/predict",
        params={"model_name": MODEL_NAME, "model_version": MODEL_VERSION},
        headers={"Content-Type": "application/json"},
        json=payload
    )
    
    return response.json()

def detect_ai_image_url(image_url, task_id=None):
    """Detect AI generation in image using URL"""
    payload = {
        "task_id": task_id or f"task_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "timestamp": datetime.now().isoformat() + "Z",
        "data": {
            "type": "image",
            "payload": image_url
        }
    }
    
    response = requests.post(
        f"{BASE_URL}/predict",
        params={"model_name": MODEL_NAME, "model_version": MODEL_VERSION},
        headers={"Content-Type": "application/json"},
        json=payload
    )
    
    return response.json()

# Example usage
if __name__ == "__main__":
    # Check health
    health = health_check()
    print(f"API Health: {health}")
    
    # Detect AI in image URL
    result = detect_ai_image_url("https://example.com/test-image.jpg")
    print(f"Detection Result: {result}")
```

```javascript JavaScript
const API_BASE_URL = 'http://localhost:8000';
const MODEL_NAME = 'default';
const MODEL_VERSION = 'v0.1';

// Health Check
async function healthCheck() {
  try {
    const response = await fetch(`${API_BASE_URL}/health`);
    return await response.json();
  } catch (error) {
    console.error('Health check failed:', error);
    throw error;
  }
}

// Detect AI Image (Base64)
async function detectAIImageBase64(imageBase64, taskId = null) {
  const payload = {
    task_id: taskId || `task_${Date.now()}`,
    timestamp: new Date().toISOString(),
    data: {
      type: 'image',
      payload: imageBase64
    }
  };

  try {
    const response = await fetch(
      `${API_BASE_URL}/predict?model_name=${MODEL_NAME}&model_version=${MODEL_VERSION}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(payload)
      }
    );
    
    return await response.json();
  } catch (error) {
    console.error('Detection failed:', error);
    throw error;
  }
}

// Detect AI Image (URL)
async function detectAIImageURL(imageURL, taskId = null) {
  const payload = {
    task_id: taskId || `task_${Date.now()}`,
    timestamp: new Date().toISOString(),
    data: {
      type: 'image',
      payload: imageURL
    }
  };

  try {
    const response = await fetch(
      `${API_BASE_URL}/predict?model_name=${MODEL_NAME}&model_version=${MODEL_VERSION}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(payload)
      }
    );
    
    return await response.json();
  } catch (error) {
    console.error('Detection failed:', error);
    throw error;
  }
}

// Example usage
async function main() {
  try {
    // Check API health
    const health = await healthCheck();
    console.log('API Health:', health);
    
    // Detect AI in image
    const result = await detectAIImageURL('https://example.com/test-image.jpg');
    console.log('Detection Result:', result);
    
  } catch (error) {
    console.error('Error:', error);
  }
}

main();
```

</CodeGroup>

## Platform-Specific Detection

### Midjourney Detection
- Recognizes distinctive artistic style and rendering patterns
- Identifies version-specific signatures (v4, v5, v6)
- Detects common Midjourney artifacts and characteristics

### DALL-E Detection
- Identifies OpenAI's specific generation patterns
- Recognizes DALL-E 2 vs DALL-E 3 differences
- Detects characteristic color palettes and styles

### Stable Diffusion Detection
- Recognizes open-source model signatures
- Identifies custom fine-tuned model variations
- Detects community-created style adaptations

### Video Platform Detection
- **Veo 3**: Identifies Google's latest video generation patterns
- **Sora**: Recognizes OpenAI's video generation characteristics
- **Runway**: Detects professional video AI tool signatures
- **Kling**: Identifies Chinese video generation platform patterns

## Real-world Applications

### Content Verification
- **News Media**: Verify authenticity of submitted images and videos
- **Social Media**: Detect and flag AI-generated content
- **Legal Evidence**: Authenticate digital evidence in legal proceedings
- **Academic Integrity**: Identify AI-generated assignments and papers

### Brand Protection
- **Trademark Infringement**: Detect AI-generated content using brand assets
- **Deepfake Advertising**: Identify unauthorized AI-generated brand content
- **Reputation Management**: Monitor for AI-generated fake content

### Content Moderation
- **Platform Safety**: Automatically flag potentially misleading AI content
- **Quality Control**: Ensure content meets authenticity standards
- **Compliance**: Meet regulatory requirements for content transparency

## Staying Current

Our detection models are continuously updated to recognize:

- **New AI Platforms**: Emerging generative AI services and tools
- **Model Updates**: New versions of existing platforms
- **Technique Evolution**: Advanced generation methods and improvements
- **Evasion Attempts**: New methods designed to bypass detection

### Update Frequency
- **Model Updates**: Weekly updates for major platforms
- **New Platform Integration**: Within 30 days of public release
- **Emergency Updates**: Same-day response to viral AI content

## Detection Accuracy by Platform

<AccordionGroup>
  <Accordion title="Image Platforms">
    - **Midjourney**: 95.2% accuracy
    - **DALL-E**: 93.8% accuracy
    - **Stable Diffusion**: 91.4% accuracy
    - **Adobe Firefly**: 89.7% accuracy
  </Accordion>

  <Accordion title="Video Platforms">
    - **Google Veo 3**: 88.9% accuracy
    - **OpenAI Sora**: 87.3% accuracy
    - **Runway ML**: 85.6% accuracy
    - **Kling AI**: 84.2% accuracy
  </Accordion>

  <Accordion title="Text Models">
    - **GPT-4**: 87.5% accuracy
    - **Claude**: 85.9% accuracy
    - **Gemini**: 84.3% accuracy
    - **Other LLMs**: 82.1% average
  </Accordion>
</AccordionGroup>

## Integration Best Practices

<CardGroup cols={2}>
  <Card
    title="Regular Updates"
    icon="refresh"
  >
    Keep detection models updated as new AI platforms emerge
  </Card>
  <Card
    title="Multi-Platform Analysis"
    icon="layer-group"
  >
    Check content against multiple platform signatures for comprehensive detection
  </Card>
  <Card
    title="Confidence Thresholds"
    icon="gauge-high"
  >
    Set appropriate confidence levels based on your use case requirements
  </Card>
  <Card
    title="Human Review"
    icon="user-check"
  >
    Implement human verification for borderline detection results
  </Card>
</CardGroup>

## API Reference

<Card
  title="Complete API Reference"
  icon="code"
  href="/api-reference/endpoint/ai-content-detection"
>
  Explore all AI content detection endpoints and examples
</Card>

---

<div style={{textAlign: 'center', marginTop: '2rem', paddingTop: '1rem', borderTop: '1px solid #e5e7eb', color: '#6b7280', fontSize: '0.875rem'}}>
  author by Fuliang Trevor Xu and Zebang Jasper Hu
</div> 